# show the created cluster in the console, and the connect button
# copy the command or agree to open in cloud shell.  Point out is just standard command:

gcloud container clusters get-credentials cluster-demo --zone us-central1-a --project kr-dr-temp-hip

# now we can run commands, and since we already have our containers, lets run one of them
# point out we're passing in the env variable, just as we did with docker.

kubectl run --image=gcr.io/kr-dr-temp-hip/ui:v0.1 frontend --port=8080 --env="GOOGLE_CLOUD_PROJECT=kr-dr-temp-hip"

# and let's look at the result... No IP address exposed for us...

kubectl get pods

# then ssh in and use to show it running

kubectl exec -it [podName] -- /bin/bash

# and use curl to show it running

curl http://127.0.0.1:8080/

# then return to cloud shell

exit

# time to scale our pod to handle greater load...

kubectl scale deployment --replicas=5 frontend 

# and the results...

kubectl get pods

#and down again

 kubectl scale deployment --replicas=2 frontend

# and the results...

kubectl get pods

#and up again

kubectl scale deployment --replicas=4 frontend
 
# we could do this all day :-)

kubectl get pods

# problem: we still don't have any way to access these pods apart from ssh
# time to expose the deployment

kubectl expose deployment frontend --port=8080 --target-port=8080 --type=LoadBalancer


# note the message: 'service "frontend" exposed'.
# run the following command repeatedly until external ip assigned. it may take a while

kubectl get services

# once you have an ip, curl to it

curl http://[ip]:8080/

# and we don't want these around long term, so....

kubectl delete service frontend
kubectl delete deployment frontend


#DONE






